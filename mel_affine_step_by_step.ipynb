{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbdb9de-85a8-4dc7-9538-2f5e7769e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ConvSTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d-based STFT that is ONNX-export-friendly and matches torch.stft\n",
    "    with center=True semantics.\n",
    "\n",
    "    Emulates torch.stft with:\n",
    "      - center=True  -> pad by n_fft//2 (via reflect/constant/replicate)\n",
    "      - normalized=False\n",
    "      - onesided=True  (we build only positive frequencies)\n",
    "      - return_complex=False (emit real/imag via two filterbanks)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft: int = 1024,\n",
    "        hop_length: int = 320,\n",
    "        win_length: int = 800,\n",
    "        window: Optional[torch.Tensor] = None,\n",
    "        pad_center: bool = True,\n",
    "        pad_mode: str = \"reflect\",   # \"reflect\" matches torchaudio center-padding\n",
    "        pad_value: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert win_length <= n_fft, \"win_length must be <= n_fft\"\n",
    "        assert pad_mode in (\"constant\", \"reflect\", \"replicate\"), \"Unsupported pad_mode\"\n",
    "\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.hop_length = int(hop_length)\n",
    "        self.win_length = int(win_length)\n",
    "        self.pad_center = bool(pad_center)\n",
    "        self.pad_mode = pad_mode\n",
    "        self.pad_value = float(pad_value)\n",
    "\n",
    "        # Window (make sure periodic=True to match torchaudio)\n",
    "        if window is None:\n",
    "            window = torch.hann_window(win_length, periodic=True, dtype=torch.float32)\n",
    "        else:\n",
    "            window = window.to(dtype=torch.float32)\n",
    "        self.register_buffer(\"window\", window, persistent=False)\n",
    "\n",
    "        # Build Fourier basis for positive freqs [0..n_fft//2], window centered in n_fft kernel\n",
    "        num_bins = self.n_fft // 2 + 1\n",
    "        offset = (self.n_fft - self.win_length) // 2\n",
    "        win_full = torch.zeros(self.n_fft, dtype=torch.float32)\n",
    "        win_full[offset:offset + self.win_length] = self.window\n",
    "\n",
    "        # n over 0..n_fft-1, k over 0..num_bins-1\n",
    "        n = torch.arange(self.n_fft, dtype=torch.float32).unsqueeze(0)   # [1, n_fft]\n",
    "        k = torch.arange(num_bins, dtype=torch.float32).unsqueeze(1)     # [num_bins, 1]\n",
    "        ang = 2 * torch.pi * (k @ (n / float(self.n_fft)))               # [num_bins, n_fft]\n",
    "\n",
    "        cos_k = torch.cos(ang) * win_full                                # [num_bins, n_fft]\n",
    "        sin_k = -torch.sin(ang) * win_full                               # [num_bins, n_fft]\n",
    "\n",
    "        weight = torch.cat([cos_k, sin_k], dim=0).unsqueeze(1)           # [2*num_bins, 1, n_fft]\n",
    "        self.register_buffer(\"fourier_basis\", weight.contiguous())\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, T] waveform\n",
    "\n",
    "        Returns:\n",
    "            stft_out: [B, F, frames, 2]  (real, imag)\n",
    "        \"\"\"\n",
    "        B, T = x.shape\n",
    "\n",
    "        # center=True -> pad by n_fft//2 using chosen pad_mode\n",
    "        if self.pad_center:\n",
    "            pad = self.n_fft // 2\n",
    "            if self.pad_mode == \"constant\":\n",
    "                x = F.pad(x, (pad, pad), mode=\"constant\", value=self.pad_value)\n",
    "            else:\n",
    "                x = F.pad(x, (pad, pad), mode=self.pad_mode)\n",
    "\n",
    "        W = self.fourier_basis.to(dtype=x.dtype, device=x.device)  # [2*F, 1, n_fft]\n",
    "\n",
    "        y = F.conv1d(\n",
    "            x.unsqueeze(1),      # [B, 1, T']\n",
    "            W,                   # [2*F, 1, n_fft]\n",
    "            bias=None,\n",
    "            stride=self.hop_length,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "        )  # -> [B, 2*F, frames]\n",
    "\n",
    "        num_bins = self.n_fft // 2 + 1\n",
    "        frames = y.shape[-1]\n",
    "        y = y.view(B, 2, num_bins, frames)\n",
    "        real = y[:, 0, :, :]\n",
    "        imag = y[:, 1, :, :]\n",
    "        stft_out = torch.stack([real, imag], dim=-1)  # [B, F, frames, 2]\n",
    "        return stft_out\n",
    "\n",
    "\n",
    "class MelSpectrogramMatched(nn.Module):\n",
    "    \"\"\"\n",
    "    ONNX-friendly Mel front end that matches torchaudio.transforms.MelSpectrogram\n",
    "    numerics (to floating-point tolerance).\n",
    "\n",
    "    Steps: STFT -> |X|^power -> Mel-projection -> (optional) depthwise affine -> (optional) log\n",
    "\n",
    "    Key matching details:\n",
    "      - Window periodicity: Hann(periodic=True)\n",
    "      - center=True, pad_mode=\"reflect\"\n",
    "      - normalized=False (no FFT normalization)\n",
    "      - onesided=True (only positive frequencies)\n",
    "      - power exponent applied to magnitude (matches torchaudio)\n",
    "      - Mel filter via torchaudio.functional.melscale_fbanks\n",
    "\n",
    "    Args mirror torchaudio.MelSpectrogram; pass the same values to match exactly.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate: int = 16000,\n",
    "        n_fft: int = 1024,\n",
    "        win_length: Optional[int] = 1024,\n",
    "        hop_length: Optional[int] = 512,\n",
    "        f_min: float = 0.0,\n",
    "        f_max: Optional[float] = None,\n",
    "        pad: int = 0,                     # unused (we emulate center-padding instead)\n",
    "        n_mels: int = 64,\n",
    "        window_fn=torch.hann_window,      # keep for API symmetry; we always use Hann(periodic=True)\n",
    "        power: float = 2.0,               # applied to |X| (magnitude)\n",
    "        normalized: bool = False,         # keep False to match default\n",
    "        center: bool = True,\n",
    "        pad_mode: str = \"reflect\",\n",
    "        onesided: bool = True,            # fixed True in our implementation\n",
    "        norm: Optional[str] = None,       # e.g., None or \"slaney\"\n",
    "        mel_scale: str = \"htk\",           # \"htk\" or \"slaney\"\n",
    "        apply_log: bool = True,           # optional log compression\n",
    "        log_eps: float = 1e-6,            # used for log safety\n",
    "        learn_affine: bool = False,       # optional per-mel affine after mel projection\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert onesided, \"This implementation assumes onesided=True.\"\n",
    "        assert not normalized, \"This STFT path matches normalized=False.\"\n",
    "\n",
    "        self.sample_rate = int(sample_rate)\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.win_length = int(win_length) if win_length is not None else int(n_fft)\n",
    "        self.hop_length = int(hop_length) if hop_length is not None else self.win_length // 2\n",
    "        self.f_min = float(f_min)\n",
    "        self.f_max = float(self.sample_rate / 2.0 if f_max is None else f_max)\n",
    "        self.n_mels = int(n_mels)\n",
    "        self.power = float(power)\n",
    "        self.center = bool(center)\n",
    "        self.pad_mode = pad_mode\n",
    "        self.norm = norm\n",
    "        self.mel_scale = mel_scale\n",
    "        self.apply_log = bool(apply_log)\n",
    "        self.log_eps = float(log_eps)\n",
    "        self.learn_affine = bool(learn_affine)\n",
    "\n",
    "        # 1) STFT using ConvSTFT\n",
    "        self.stft = ConvSTFT(\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            window=torch.hann_window(self.win_length, periodic=True),\n",
    "            pad_center=self.center,\n",
    "            pad_mode=self.pad_mode,\n",
    "            pad_value=0.0,\n",
    "        )\n",
    "\n",
    "        # 2) Mel filterbank (F, M)\n",
    "        fb = torchaudio.functional.melscale_fbanks(\n",
    "            n_freqs=self.n_fft // 2 + 1,\n",
    "            f_min=self.f_min,\n",
    "            f_max=self.f_max,\n",
    "            n_mels=self.n_mels,\n",
    "            sample_rate=self.sample_rate,\n",
    "            norm=self.norm,\n",
    "            mel_scale=self.mel_scale,\n",
    "        )  # shape: (F, M)\n",
    "        self.register_buffer(\"mel_fb\", fb, persistent=False)\n",
    "\n",
    "        # 3) Optional per-mel affine (depthwise 1x1 conv), identity init\n",
    "        if self.learn_affine:\n",
    "            self.affine = nn.Conv1d(self.n_mels, self.n_mels, kernel_size=1, groups=self.n_mels, bias=True)\n",
    "            nn.init.ones_(self.affine.weight)\n",
    "            nn.init.zeros_(self.affine.bias)\n",
    "        else:\n",
    "            self.affine = None\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            wav: (B, T) float32/float16 (any floating type)\n",
    "\n",
    "        Returns:\n",
    "            (B, n_mels, frames) if apply_log=True -> log-mel, else linear mel power\n",
    "        \"\"\"\n",
    "        # STFT\n",
    "        stft = self.stft(wav)                        # (B, F, frames, 2)\n",
    "        mag2 = (stft ** 2).sum(-1)                   # power spectrum: |X|^2  -> (B, F, frames)\n",
    "\n",
    "        # Apply power exponent on magnitude to match torchaudio: |X|^power\n",
    "        if self.power == 2.0:\n",
    "            S = mag2\n",
    "        elif self.power == 1.0:\n",
    "            S = torch.sqrt(torch.clamp_min(mag2, 0.0))\n",
    "        else:\n",
    "            # general case: |X|^p = (|X|^2)^(p/2)\n",
    "            S = torch.clamp_min(mag2, 0.0) ** (self.power / 2.0)  # (B, F, frames)\n",
    "\n",
    "        # Mel projection (B, F, T) -> (B, T, F) @ (F, M) -> (B, T, M) -> (B, M, T)\n",
    "        mel_fb = self.mel_fb.to(dtype=S.dtype, device=S.device)\n",
    "        mel = torch.matmul(S.transpose(1, 2), mel_fb).transpose(1, 2)    # (B, M, frames)\n",
    "\n",
    "        # Optional per-mel affine in linear domain (be careful with log)\n",
    "        if self.affine is not None:\n",
    "            mel = self.affine(mel)\n",
    "\n",
    "        if self.apply_log:\n",
    "            # Safe log (matching common log-mel: natural log by default)\n",
    "            mel = torch.log(torch.clamp_min(mel, self.log_eps))\n",
    "\n",
    "        return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6b7738-e522-43c5-915c-348fa81bfdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40, 101])\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.randn(1, 16000)\n",
    "model = MelSpectrogramMatched(\n",
    "        sample_rate=16000,\n",
    "        n_fft=512,\n",
    "        win_length=480,\n",
    "        hop_length=160,\n",
    "        n_mels=40,\n",
    "       log_eps=1e-5,\n",
    "        learn_affine=True,     # enable the learnable per-mel affine\n",
    "    ).eval()\n",
    "\n",
    "output = model(dummy)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704629a4-7641-496a-9be5-57d5ae8bbd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:308: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/onnx/utils.py:657: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/onnx/utils.py:1127: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "model = MelSpectrogramMatched(sample_rate=16000,\n",
    "        n_fft=512,\n",
    "        win_length=480,\n",
    "        hop_length=160,\n",
    "        n_mels=40,\n",
    "       log_eps=1e-5,\n",
    "        learn_affine=True,).eval()\n",
    "dummy = torch.randn(1, 16000)\n",
    "torch.onnx.export(\n",
    "    model, dummy, \"mel.onnx\",\n",
    "    input_names=[\"wav\"], output_names=[\"mel\"],\n",
    "    dynamic_axes={\"wav\": {1: \"T\"}, \"mel\": {2: \"frames\"}},\n",
    "    opset_version=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdb95c-ad9e-4e67-bcaf-fdd6eaa9ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c44c5b-1cd7-41de-82f0-2f9862b68d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from typing import Optional\n",
    "\n",
    "class ConvSTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d-based STFT that is ONNX-export-friendly.\n",
    "\n",
    "    Emulates torch.stft with:\n",
    "      - center=True -> pad by n_fft//2 on both ends\n",
    "      - normalized=False\n",
    "      - return_complex=False (we output real/imag via two filter banks)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft: int = 1024,\n",
    "        hop_length: int = 320,\n",
    "        win_length: int = 800,\n",
    "        window: Optional[torch.Tensor] = None,\n",
    "        pad_center: bool = True,\n",
    "        pad_mode: str = \"reflect\",   # \"reflect\" matches torch.stft(center=True); or \"constant\"\n",
    "        pad_value: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert win_length <= n_fft, \"win_length must be <= n_fft\"\n",
    "        assert pad_mode in (\"constant\", \"reflect\", \"replicate\"), \"Unsupported pad_mode\"\n",
    "\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.hop_length = int(hop_length)\n",
    "        self.win_length = int(win_length)\n",
    "        self.pad_center = bool(pad_center)\n",
    "        self.pad_mode = pad_mode\n",
    "        self.pad_value = float(pad_value)\n",
    "\n",
    "        # Window\n",
    "        if window is None:\n",
    "            window = torch.hann_window(win_length, periodic=True, dtype=torch.float32)\n",
    "        else:\n",
    "            window = window.to(dtype=torch.float32)\n",
    "        self.register_buffer(\"window\", window, persistent=False)\n",
    "\n",
    "        # Build Fourier basis for positive freqs [0..n_fft//2], window centered inside n_fft kernel\n",
    "        num_bins = n_fft // 2 + 1\n",
    "        offset = (n_fft - win_length) // 2\n",
    "        win_full = torch.zeros(n_fft, dtype=torch.float32)\n",
    "        win_full[offset:offset + win_length] = self.window\n",
    "\n",
    "        n = torch.arange(n_fft, dtype=torch.float32).unsqueeze(0)     # [1, n_fft]\n",
    "        k = torch.arange(num_bins, dtype=torch.float32).unsqueeze(1)  # [num_bins, 1]\n",
    "        ang = 2 * torch.pi * (k @ (n / float(n_fft)))                 # [num_bins, n_fft]\n",
    "\n",
    "        cos_kernels = torch.cos(ang) * win_full                       # [num_bins, n_fft]\n",
    "        sin_kernels = -torch.sin(ang) * win_full                      # [num_bins, n_fft]\n",
    "\n",
    "        weight = torch.cat([cos_kernels, sin_kernels], dim=0).unsqueeze(1)  # [2*num_bins, 1, n_fft]\n",
    "        self.register_buffer(\"fourier_basis\", weight.contiguous())\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, T] waveform\n",
    "\n",
    "        Returns:\n",
    "            stft_out: [B, num_bins, frames, 2]  where last dim is (real, imag)\n",
    "        \"\"\"\n",
    "        B, T = x.shape\n",
    "\n",
    "        # center=True -> pad by n_fft//2\n",
    "        if self.pad_center:\n",
    "            pad = self.n_fft // 2\n",
    "            if self.pad_mode == \"constant\":\n",
    "                x = F.pad(x, (pad, pad), mode=\"constant\", value=self.pad_value)\n",
    "            else:\n",
    "                x = F.pad(x, (pad, pad), mode=self.pad_mode)\n",
    "\n",
    "        fourier_basis = self.fourier_basis.to(dtype=x.dtype, device=x.device)\n",
    "\n",
    "        y = F.conv1d(\n",
    "            x.unsqueeze(1),      # [B, 1, T']\n",
    "            fourier_basis,       # [2*F, 1, n_fft]\n",
    "            bias=None,\n",
    "            stride=self.hop_length,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "        )  # -> [B, 2*F, frames]\n",
    "\n",
    "        num_bins = self.n_fft // 2 + 1\n",
    "        frames = y.shape[-1]\n",
    "        y = y.view(B, 2, num_bins, frames)\n",
    "        real = y[:, 0, :, :]\n",
    "        imag = y[:, 1, :, :]\n",
    "        stft_out = torch.stack([real, imag], dim=-1)  # [B, F, frames, 2]\n",
    "        return stft_out\n",
    "\n",
    "\n",
    "class LogMelAffine(nn.Module):\n",
    "    \"\"\"\n",
    "    STFT -> Mel -> (optional affine) -> Log\n",
    "    The affine is applied on linear Mel. Consider clamping to avoid log on negative values.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate=16000,\n",
    "        n_fft=1024,\n",
    "        win_length=400,\n",
    "        hop_length=160,\n",
    "        n_mels=64,\n",
    "        f_min=0.0,\n",
    "        f_max=None,\n",
    "        mel_scale=\"htk\",      # set to match your reference\n",
    "        norm=None,            # set to match your reference\n",
    "        log_eps=1e-5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.log_eps = log_eps\n",
    "        \n",
    "        # 1) STFT\n",
    "        self.stft = ConvSTFT(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            window=torch.hann_window(win_length, periodic=True),\n",
    "            pad_center=True,\n",
    "            pad_mode=\"reflect\",\n",
    "            pad_value=0.0,\n",
    "        )\n",
    "\n",
    "        # 2) Mel filterbank\n",
    "        fb = torchaudio.functional.melscale_fbanks(\n",
    "            n_freqs=n_fft // 2 + 1,\n",
    "            f_min=f_min,\n",
    "            f_max=(sample_rate / 2.0) if f_max is None else f_max,\n",
    "            n_mels=n_mels,\n",
    "            sample_rate=sample_rate,\n",
    "            norm=norm,\n",
    "            mel_scale=mel_scale\n",
    "        )  # (F, M)\n",
    "        self.register_buffer(\"mel_fb\", fb, persistent=False)\n",
    "\n",
    "        # 3) Per-mel affine (depthwise 1x1)\n",
    "        self.affine = nn.Conv1d(n_mels, n_mels, kernel_size=1, groups=n_mels, bias=True)\n",
    "        nn.init.ones_(self.affine.weight)  # scale=1\n",
    "        nn.init.zeros_(self.affine.bias)   # bias=0\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        wav: (B, T) float32\n",
    "        returns: (B, M, T') log-mel aligned\n",
    "        \"\"\"\n",
    "        # STFT -> power\n",
    "        stft = self.stft(wav)              # (B, F, T', 2)\n",
    "        power = (stft ** 2).sum(-1)        # (B, F, T')\n",
    "\n",
    "        # Mel projection (use GEMM-friendly matmul)\n",
    "        mel_fb = self.mel_fb.to(dtype=power.dtype, device=power.device)  # ensure dtype/device match\n",
    "        mel = torch.matmul(power.transpose(1, 2), mel_fb).transpose(1, 2)  # (B, M, T')\n",
    "\n",
    "        # Per-mel affine\n",
    "        mel = self.affine(mel)             # (B, M, T')\n",
    "\n",
    "        # (Safer) clamp to avoid log of <= 0 after affine\n",
    "        mel = torch.clamp(mel, min=self.log_eps)\n",
    "\n",
    "        # Log compression\n",
    "        mel = torch.log(mel)               # (B, M, T')\n",
    "        return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf08d3-7942-4a25-85a4-97c6440fd047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24833177-1e73-47e8-a657-8ccbf0bd4e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb66ec-bd3c-47f2-b40c-1743afd948c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
