{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f700ccb1-c853-4287-b45f-d6681e1dc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d3fbb7-2f5b-450e-8848-cdf1a599871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d-based STFT that is ONNX-export-friendly.\n",
    "\n",
    "    Emulates torch.stft with:\n",
    "      - center=True  -> zero pad by n_fft//2 at both ends\n",
    "      - normalized=False\n",
    "      - return_complex=False (we output real/imag via two filter banks)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft: int = 1024,\n",
    "        hop_length: int = 320,\n",
    "        win_length: int = 800,\n",
    "        window: torch.Tensor | None = None,\n",
    "        pad_center: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert win_length <= n_fft, \"win_length must be <= n_fft\"\n",
    "\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.hop_length = int(hop_length)\n",
    "        self.win_length = int(win_length)\n",
    "        self.pad_center = bool(pad_center)\n",
    "\n",
    "        # Window\n",
    "        if window is None:\n",
    "            window = torch.hann_window(win_length, periodic=False, dtype=torch.float32)\n",
    "        else:\n",
    "            window = window.to(dtype=torch.float32)\n",
    "        self.register_buffer(\"window\", window, persistent=False)\n",
    "\n",
    "        # Build Fourier basis for positive frequencies [0 .. n_fft//2]\n",
    "        # Real kernels:  window[n] * cos(2πkn/N)\n",
    "        # Imag kernels: -window[n] * sin(2πkn/N)\n",
    "        \n",
    "        # Build Fourier basis for positive frequencies [0..n_fft//2]\n",
    "        num_bins = n_fft // 2 + 1\n",
    "        \n",
    "        # Center the window inside an n_fft frame\n",
    "        offset = (n_fft - win_length) // 2\n",
    "        win_full = torch.zeros(n_fft, dtype=torch.float32)\n",
    "        win_full[offset:offset+win_length] = self.window  # centered window\n",
    "        \n",
    "        # n over 0..n_fft-1, k over 0..num_bins-1\n",
    "        n = torch.arange(n_fft, dtype=torch.float32).unsqueeze(0)  # [1, n_fft]\n",
    "        k = torch.arange(num_bins, dtype=torch.float32).unsqueeze(1)  # [num_bins, 1]\n",
    "        ang = 2 * math.pi * k @ (n / float(n_fft))  # [num_bins, n_fft]\n",
    "        \n",
    "        cos_kernels = torch.cos(ang) * win_full      # [num_bins, n_fft]\n",
    "        sin_kernels = -torch.sin(ang) * win_full     # [num_bins, n_fft]\n",
    "        \n",
    "        weight = torch.cat([cos_kernels, sin_kernels], dim=0).unsqueeze(1)  # [2*num_bins, 1, n_fft]\n",
    "        self.register_buffer(\"fourier_basis\", weight.contiguous(), persistent=False)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, T] waveform\n",
    "\n",
    "        Returns:\n",
    "            stft_out: [B, num_bins, frames, 2]  where last dim is (real, imag)\n",
    "        \"\"\"\n",
    "        B, T = x.shape\n",
    "\n",
    "        # center=True -> zero pad by n_fft//2\n",
    "        if self.pad_center:\n",
    "            pad = self.n_fft // 2\n",
    "            x = F.pad(x, (pad, pad), mode=\"constant\", value=0.0)  # [B, T + 2*pad]\n",
    "\n",
    "        # Convolution to compute dot product with each Fourier kernel at each frame\n",
    "        # Input must be [B, 1, T]\n",
    "        y = F.conv1d(\n",
    "            x.unsqueeze(1),                       # [B, 1, T+pad*2]\n",
    "            self.fourier_basis,                   # [2*F, 1, win_length]\n",
    "            bias=None,\n",
    "            stride=self.hop_length,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "        )  # -> [B, 2*F, frames]\n",
    "\n",
    "        num_bins = self.n_fft // 2 + 1\n",
    "        frames = y.shape[-1]\n",
    "        y = y.view(B, 2, num_bins, frames)        # [B, 2, F, frames]\n",
    "        real = y[:, 0, :, :]                      # [B, F, frames]\n",
    "        imag = y[:, 1, :, :]                      # [B, F, frames]\n",
    "\n",
    "        # Pack to match torch.stft(return_complex=False) output layout\n",
    "        stft_out = torch.stack([real, imag], dim=-1)  # [B, F, frames, 2]\n",
    "        return stft_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecf86f4-c264-405d-aa52-fe2ae63874c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "\n",
    "# Assumes your ConvSTFT is patched for Option A: n_fft-length kernels with centered window\n",
    "class LogMelSpectrogramConvSTFT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_mels: int = 128,\n",
    "        sr: int = 32000,\n",
    "        win_length: int = 800,\n",
    "        hopsize: int = 320,\n",
    "        n_fft: int = 1024,\n",
    "        fmin: float = 0.0,\n",
    "        fmax: float | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if fmax is None:\n",
    "            fmax = sr // 2\n",
    "\n",
    "        self.n_mels = int(n_mels)\n",
    "        self.sr = int(sr)\n",
    "        self.win_length = int(win_length)\n",
    "        self.hopsize = int(hopsize)\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.fmin = float(fmin)\n",
    "\n",
    "        nyquist = sr // 2\n",
    "        if fmax is None:\n",
    "            fmax = nyquist\n",
    "        elif fmax > nyquist:\n",
    "            print(f\"[LogMel] fmax={fmax} > Nyquist={nyquist}. Clamping to Nyquist.\")\n",
    "            fmax = float(nyquist)\n",
    "        self.fmax = float(fmax)\n",
    "\n",
    "        assert 0.0 <= self.fmin < self.fmax <= (self.sr / 2), \\\n",
    "            f\"Invalid band: fmin={self.fmin}, fmax={self.fmax}, nyquist={self.sr/2}\"\n",
    "\n",
    "        # Pre-emphasis kernel y[t] = x[t] - 0.97*x[t-1]\n",
    "        self.register_buffer(\n",
    "            \"preemphasis_kernel\",\n",
    "            torch.tensor([[[-0.97, 1.0]]], dtype=torch.float32),\n",
    "            persistent=False\n",
    "        )\n",
    "\n",
    "        # STFT via conv: ConvSTFT must center win inside n_fft and use n_fft-length kernels internally\n",
    "        self.stft = ConvSTFT(\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hopsize,\n",
    "            win_length=self.win_length,\n",
    "            window=torch.hann_window(self.win_length, periodic=False, dtype=torch.float32),\n",
    "            pad_center=True,\n",
    "        )\n",
    "\n",
    "        # Kaldi mel filter bank (Nyquist excluded), then pad Nyquist\n",
    "        mel_bins, _ = torchaudio.compliance.kaldi.get_mel_banks(\n",
    "            num_bins=self.n_mels,\n",
    "            window_length_padded=self.n_fft,\n",
    "            sample_freq=self.sr,\n",
    "            low_freq=self.fmin,\n",
    "            high_freq=self.fmax,\n",
    "            vtln_low=100.0,\n",
    "            vtln_high=-500.0,\n",
    "            vtln_warp_factor=1.0,\n",
    "        )\n",
    "        mel_bins = F.pad(mel_bins, (0, 1), value=0.0)  # -> [n_mels, n_fft//2 + 1]\n",
    "        self.register_buffer(\"mel_basis\", mel_bins.to(torch.float32), persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Current behavior (length T-1) to match EfficientAT reference:\n",
    "        x = F.conv1d(x.unsqueeze(1), self.preemphasis_kernel).squeeze(1)\n",
    "\n",
    "        # STFT -> power\n",
    "        stft_out = self.stft(x)               # [B, F, frames, 2]\n",
    "        power = (stft_out ** 2).sum(dim=-1)   # [B, F, frames]\n",
    "\n",
    "        # Mel projection (use correct einsum string, keep dtype/device aligned)\n",
    "        mel_basis = self.mel_basis.to(dtype=power.dtype, device=power.device)  # [M, F]\n",
    "        mel = torch.einsum('mf,bft->bmt', mel_basis, power)                    # [B, M, T]\n",
    "\n",
    "        # Log compression + normalization\n",
    "        log_mel = (mel + 1e-5).log()\n",
    "        log_mel = (log_mel + 4.5) / 5.0\n",
    "        return log_mel\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def power_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.conv1d(x.unsqueeze(1), self.preemphasis_kernel).squeeze(1)\n",
    "        stft_out = self.stft(x)\n",
    "        power = (stft_out ** 2).sum(dim=-1)\n",
    "        return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa3f655-e846-4aed-b0c5-6238c9df44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paste in your ConvSTFT and LogMelSpectrogramConvSTFT here, or import them ----\n",
    "# from your_module import ConvSTFT, LogMelSpectrogramConvSTFT\n",
    "#\n",
    "# NOTE: Ensure ConvSTFT uses n_fft-length kernels with the window centered inside n_fft (Option A).\n",
    "# Also ensure LogMelSpectrogramConvSTFT uses mel projection with einsum: torch.einsum('mf, bft -> bmt', mel_basis, power).\n",
    "\n",
    "# ----- Reference: AugmentMelSTFT from EfficientAT (as provided by you) -----\n",
    "class AugmentMelSTFT(nn.Module):\n",
    "    def __init__(self, n_mels=128, sr=32000, win_length=800, hopsize=320, n_fft=1024, freqm=48, timem=192,\n",
    "                 fmin=0.0, fmax=None, fmin_aug_range=10, fmax_aug_range=2000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.win_length = win_length\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.sr = sr\n",
    "        self.fmin = fmin\n",
    "        if fmax is None:\n",
    "            fmax = sr // 2 - fmax_aug_range // 2\n",
    "            print(f\"Warning: FMAX is None setting to {fmax} \")\n",
    "        self.fmax = fmax\n",
    "        self.hopsize = hopsize\n",
    "\n",
    "        self.register_buffer('window', torch.hann_window(win_length, periodic=False), persistent=False)\n",
    "\n",
    "        assert fmin_aug_range >= 1, f\"fmin_aug_range={fmin_aug_range} should be >=1; 1 means no augmentation\"\n",
    "        assert fmax_aug_range >= 1, f\"fmax_aug_range={fmax_aug_range} should be >=1; 1 means no augmentation\"\n",
    "        self.fmin_aug_range = fmin_aug_range\n",
    "        self.fmax_aug_range = fmax_aug_range\n",
    "\n",
    "        self.register_buffer(\"preemphasis_coefficient\", torch.as_tensor([[[-.97, 1]]]), persistent=False)\n",
    "\n",
    "        if freqm == 0:\n",
    "            self.freqm = torch.nn.Identity()\n",
    "        else:\n",
    "            self.freqm = torchaudio.transforms.FrequencyMasking(freqm, iid_masks=True)\n",
    "        if timem == 0:\n",
    "            self.timem = torch.nn.Identity()\n",
    "        else:\n",
    "            self.timem = torchaudio.transforms.TimeMasking(timem, iid_masks=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pre-emphasis (length reduces by 1 sample)\n",
    "        x = nn.functional.conv1d(x.unsqueeze(1), self.preemphasis_coefficient).squeeze(1)\n",
    "\n",
    "        # Reference STFT\n",
    "        x = torch.stft(\n",
    "            x,\n",
    "            self.n_fft,\n",
    "            hop_length=self.hopsize,\n",
    "            win_length=self.win_length,\n",
    "            center=True,\n",
    "            normalized=False,\n",
    "            window=self.window,\n",
    "            return_complex=False,\n",
    "        )\n",
    "        x = (x ** 2).sum(dim=-1)  # power: [B, F, T]\n",
    "\n",
    "        # Aug ranges are ignored in eval mode\n",
    "        fmin = self.fmin + torch.randint(self.fmin_aug_range, (1,)).item()\n",
    "        fmax = self.fmax + self.fmax_aug_range // 2 - torch.randint(self.fmax_aug_range, (1,)).item()\n",
    "        if not self.training:\n",
    "            fmin = self.fmin\n",
    "            fmax = self.fmax\n",
    "\n",
    "        # Kaldi mel basis (Nyquist excluded) then pad Nyquist bin\n",
    "        mel_basis, _ = torchaudio.compliance.kaldi.get_mel_banks(\n",
    "            self.n_mels,  self.n_fft, self.sr,\n",
    "            fmin, fmax,\n",
    "            vtln_low=100.0, vtln_high=-500., vtln_warp_factor=1.0\n",
    "        )\n",
    "        mel_basis = torch.nn.functional.pad(mel_basis, (0, 1), mode='constant', value=0)  # [M, F]\n",
    "\n",
    "        # Project to mel\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            mel_basis = torch.as_tensor(mel_basis, device=x.device, dtype=x.dtype)  # [M, F]\n",
    "            melspec = torch.einsum('mf, bft -> bmt', mel_basis, x)  # [B, M, T]\n",
    "\n",
    "        # Log compression\n",
    "        melspec = (melspec + 1e-5).log()\n",
    "\n",
    "        # (Optional) masking only in training mode\n",
    "        if self.training:\n",
    "            melspec = self.freqm(melspec)\n",
    "            melspec = self.timem(melspec)\n",
    "\n",
    "        # Fast normalization\n",
    "        melspec = (melspec + 4.5) / 5.0\n",
    "        return melspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45911b3f-3ee8-45e7-a257-ad33382254c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Comparison Utilities ----------\n",
    "def compute_metrics(a: torch.Tensor, b: torch.Tensor, eps_mask: float = 1e-3):\n",
    "    \"\"\"\n",
    "    a, b: tensors of the same shape\n",
    "    Returns a dict of absolute and (masked) relative error metrics.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        abs_err = (a - b).abs()\n",
    "        max_abs = abs_err.max().item()\n",
    "        mean_abs = abs_err.mean().item()\n",
    "\n",
    "        # Masked relative error to avoid division by tiny reference values\n",
    "        ref = b.abs()\n",
    "        mask = ref > eps_mask\n",
    "        if mask.any():\n",
    "            rel_err = abs_err[mask] / ref[mask]\n",
    "            max_rel = rel_err.max().item()\n",
    "            mean_rel = rel_err.mean().item()\n",
    "        else:\n",
    "            max_rel = float('nan')\n",
    "            mean_rel = float('nan')\n",
    "\n",
    "    return {\n",
    "        \"max_abs_err\": max_abs,\n",
    "        \"mean_abs_err\": mean_abs,\n",
    "        \"masked_max_rel_err\": max_rel,\n",
    "        \"masked_mean_rel_err\": mean_rel,\n",
    "    }\n",
    "\n",
    "\n",
    "def compare_logmel_modules(\n",
    "    LogMelClass,            # your LogMelSpectrogramConvSTFT class object\n",
    "    AugmentMelClass=AugmentMelSTFT,\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "    B: int = 2,\n",
    "    T: int = 16000,\n",
    "    n_mels: int = 128,\n",
    "    sr: int = 32000,\n",
    "    win_length: int = 800,\n",
    "    hopsize: int = 320,\n",
    "    n_fft: int = 1024,\n",
    "    fmin: float = 0.0,\n",
    "    fmax: float | None = None,\n",
    "    plot: bool = False,\n",
    "    also_test_float64: bool = True,\n",
    "):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Instantiate both models with the same configuration\n",
    "    ref = AugmentMelClass(\n",
    "        n_mels=n_mels, sr=sr, win_length=win_length, hopsize=hopsize, n_fft=n_fft,\n",
    "        freqm=0, timem=0,  # ensure no masking even if .train() is used\n",
    "        fmin=fmin, fmax=fmax if fmax is not None else sr // 2,\n",
    "        fmin_aug_range=1, fmax_aug_range=1,  # augmentation off effectively\n",
    "    ).to(device).eval()\n",
    "\n",
    "    test = LogMelClass(\n",
    "        n_mels=n_mels, sr=sr, win_length=win_length, hopsize=hopsize, n_fft=n_fft, fmin=fmin, fmax=fmax\n",
    "    ).to(device).eval()\n",
    "\n",
    "    # NOTE: Different constructors - your LogMelSpectrogramConvSTFT likely uses \"hopsize\" param name.\n",
    "    # If it's 'hopsize', the above passes it; if it's 'hop_length', adapt accordingly.\n",
    "\n",
    "    # Random batch\n",
    "    x = torch.randn(B, T, dtype=dtype, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Reference (torch.stft path)\n",
    "        y_ref = ref(x)             # [B, M, frames]\n",
    "\n",
    "        # Test (Conv1d STFT path)\n",
    "        y_test = test(x)           # [B, M, frames]\n",
    "\n",
    "    # Check shapes\n",
    "    assert y_ref.shape == y_test.shape, f\"Shape mismatch: ref={y_ref.shape}, test={y_test.shape}\"\n",
    "\n",
    "    # Metrics\n",
    "    metrics = compute_metrics(y_test, y_ref, eps_mask=1e-3)\n",
    "\n",
    "    # Allclose with realistic fp32 tolerances (for n_fft=1024)\n",
    "    atol = 5e-3\n",
    "    rtol = 5e-3\n",
    "    allclose = torch.allclose(y_test, y_ref, atol=atol, rtol=rtol)\n",
    "\n",
    "    print(\"=== Log-Mel: ConvSTFT vs AugmentMelSTFT (fp32) ===\")\n",
    "    print(f\"Device: {device}  DType: {dtype}\")\n",
    "    print(f\"Input:  B={B}, T={T}, sr={sr}, n_fft={n_fft}, win={win_length}, hop={hopsize}, n_mels={n_mels}\")\n",
    "    print(f\"Output shape: {y_test.shape}  (B, M, frames)\")\n",
    "    print(f\"Max abs error:          {metrics['max_abs_err']:.6e}\")\n",
    "    print(f\"Mean abs error:         {metrics['mean_abs_err']:.6e}\")\n",
    "    print(f\"Masked max rel error:   {metrics['masked_max_rel_err']:.6e} (|ref|>1e-3)\")\n",
    "    print(f\"Masked mean rel error:  {metrics['masked_mean_rel_err']:.6e} (|ref|>1e-3)\")\n",
    "    print(f\"torch.allclose:         {allclose} (atol={atol}, rtol={rtol})\")\n",
    "\n",
    "    if plot:\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            b = 0\n",
    "            fig, axs = plt.subplots(2, 3, figsize=(14, 6))\n",
    "            axs = axs.ravel()\n",
    "\n",
    "            im0 = axs[0].imshow(y_ref[b].cpu().numpy(), aspect='auto', origin='lower')\n",
    "            axs[0].set_title(\"AugmentMelSTFT (ref)\")\n",
    "            plt.colorbar(im0, ax=axs[0], fraction=0.046)\n",
    "\n",
    "            im1 = axs[1].imshow(y_test[b].cpu().numpy(), aspect='auto', origin='lower')\n",
    "            axs[1].set_title(\"LogMelSpectrogramConvSTFT (test)\")\n",
    "            plt.colorbar(im1, ax=axs[1], fraction=0.046)\n",
    "\n",
    "            diff = (y_test[b] - y_ref[b]).cpu().numpy()\n",
    "            im2 = axs[2].imshow(abs(diff), aspect='auto', origin='lower')\n",
    "            axs[2].set_title(\"|difference|\")\n",
    "            plt.colorbar(im2, ax=axs[2], fraction=0.046)\n",
    "\n",
    "            # Histograms\n",
    "            axs[3].hist(diff.flatten(), bins=100, alpha=0.7)\n",
    "            axs[3].set_title(\"Diff histogram\")\n",
    "\n",
    "            axs[4].plot((abs(diff)).mean(axis=0))\n",
    "            axs[4].set_title(\"Mean |diff| per frame\")\n",
    "\n",
    "            axs[5].plot((abs(diff)).mean(axis=1))\n",
    "            axs[5].set_title(\"Mean |diff| per mel bin\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"(Plot skipped due to error: {e})\")\n",
    "\n",
    "    # Optional: Double-precision sanity check\n",
    "    if also_test_float64:\n",
    "        x64 = x.double()\n",
    "        ref64 = ref.double()\n",
    "        test64 = test.double()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_ref64 = ref64(x64)\n",
    "            y_test64 = test64(x64)\n",
    "\n",
    "        assert y_ref64.shape == y_test64.shape\n",
    "        metrics64 = compute_metrics(y_test64, y_ref64, eps_mask=1e-9)\n",
    "        allclose64 = torch.allclose(y_test64, y_ref64, atol=1e-8, rtol=1e-8)\n",
    "\n",
    "        print(\"\\n=== Log-Mel: ConvSTFT vs AugmentMelSTFT (float64) ===\")\n",
    "        print(f\"Max abs error:          {metrics64['max_abs_err']:.6e}\")\n",
    "        print(f\"Mean abs error:         {metrics64['mean_abs_err']:.6e}\")\n",
    "        print(f\"Masked max rel error:   {metrics64['masked_max_rel_err']:.6e} (|ref|>1e-9)\")\n",
    "        print(f\"Masked mean rel error:  {metrics64['masked_mean_rel_err']:.6e} (|ref|>1e-9)\")\n",
    "        print(f\"torch.allclose:         {allclose64} (atol=1e-8, rtol=1e-8)\")\n",
    "\n",
    "    return {\n",
    "        \"fp32\": {**metrics, \"allclose\": allclose},\n",
    "        \"fp64\": {**metrics64, \"allclose\": allclose64} if also_test_float64 else None,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57c9c5c-a74d-4115-98c1-822dd2b28f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Log-Mel: ConvSTFT vs AugmentMelSTFT (fp32) ===\n",
      "Device: cuda  DType: torch.float32\n",
      "Input:  B=2, T=16000, sr=32000, n_fft=1024, win=800, hop=320, n_mels=128\n",
      "Output shape: torch.Size([2, 128, 50])  (B, M, frames)\n",
      "Max abs error:          1.290884e+00\n",
      "Mean abs error:         3.625098e-03\n",
      "Masked max rel error:   6.989396e+00 (|ref|>1e-3)\n",
      "Masked mean rel error:  4.634821e-03 (|ref|>1e-3)\n",
      "torch.allclose:         False (atol=0.005, rtol=0.005)\n",
      "\n",
      "=== Log-Mel: ConvSTFT vs AugmentMelSTFT (float64) ===\n",
      "Max abs error:          1.291029e+00\n",
      "Mean abs error:         3.624981e-03\n",
      "Masked max rel error:   6.989822e+00 (|ref|>1e-9)\n",
      "Masked mean rel error:  4.633626e-03 (|ref|>1e-9)\n",
      "torch.allclose:         False (atol=1e-8, rtol=1e-8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/functional.py:709: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /pytorch/aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n",
      "/tmp/ipykernel_43839/3714018568.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "source": [
    "results = compare_logmel_modules(LogMelSpectrogramConvSTFT, plot=False, also_test_float64=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d487ed2-f08c-4f3a-af9c-32e09d498d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "\n",
    "def compare_logmel_stepwise(\n",
    "    conv_model: LogMelSpectrogramConvSTFT,\n",
    "    ref_model: nn.Module,  # AugmentMelSTFT\n",
    "    x: torch.Tensor,\n",
    "    fmin: float,\n",
    "    fmax: float,\n",
    "    eps: float = 1e-5,\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "):\n",
    "    conv_model.eval()\n",
    "    ref_model.eval()\n",
    "\n",
    "    device = x.device\n",
    "    x = x.to(dtype)\n",
    "\n",
    "    # ----- 1) Pre-emphasis -----\n",
    "    pe_kernel = conv_model.preemphasis_kernel.to(dtype=dtype, device=device)\n",
    "    x_pe = F.conv1d(x.unsqueeze(1), pe_kernel).squeeze(1)   # match both paths\n",
    "\n",
    "    # ----- 2) STFT -----\n",
    "    # Conv path power\n",
    "    stft_conv = conv_model.stft(x_pe)                       # [B, F, T, 2]\n",
    "    power_conv = (stft_conv ** 2).sum(dim=-1)               # [B, F, T]\n",
    "\n",
    "    # Reference path power (torch.stft)\n",
    "    window = torch.hann_window(conv_model.win_length, periodic=False, dtype=dtype, device=device)\n",
    "    stft_ref = torch.stft(\n",
    "        x_pe, n_fft=conv_model.n_fft, hop_length=conv_model.hopsize, win_length=conv_model.win_length,\n",
    "        center=True, normalized=False, window=window, return_complex=False, pad_mode=\"constant\"\n",
    "    )                                                       # [B, F, T, 2]\n",
    "    power_ref = (stft_ref ** 2).sum(dim=-1)                 # [B, F, T]\n",
    "\n",
    "    print(\"Power max abs:\", (power_conv - power_ref).abs().max().item(),\n",
    "          \"mean abs:\", (power_conv - power_ref).abs().mean().item())\n",
    "\n",
    "    # ----- 3) Single shared mel basis -----\n",
    "    mel_basis, _ = torchaudio.compliance.kaldi.get_mel_banks(\n",
    "        conv_model.n_mels, conv_model.n_fft, conv_model.sr,\n",
    "        fmin, fmax, vtln_low=100.0, vtln_high=-500.0, vtln_warp_factor=1.0\n",
    "    )\n",
    "    mel_basis = F.pad(mel_basis, (0, 1), value=0.0).to(device=device, dtype=dtype)  # [M, F]\n",
    "\n",
    "    mel_conv = torch.einsum('mf,bft->bmt', mel_basis, power_conv)     # [B, M, T]\n",
    "    mel_ref  = torch.einsum('mf,bft->bmt', mel_basis, power_ref)      # [B, M, T]\n",
    "\n",
    "    print(\"Pre-log mel max abs:\", (mel_conv - mel_ref).abs().max().item(),\n",
    "          \"mean abs:\", (mel_conv - mel_ref).abs().mean().item())\n",
    "\n",
    "    # ----- 4) Apply identical log + norm -----\n",
    "    y_conv = (mel_conv + eps).log(); y_conv = (y_conv + 4.5) / 5.0\n",
    "    y_ref  = (mel_ref  + eps).log(); y_ref  = (y_ref  + 4.5) / 5.0\n",
    "\n",
    "    diff = (y_conv - y_ref).abs()\n",
    "    print(\"Log-mel max abs:\", diff.max().item(), \"mean abs:\", diff.mean().item())\n",
    "\n",
    "    # Also report masked relative error on log-mel\n",
    "    mask = y_ref.abs() > 1e-3\n",
    "    if mask.any():\n",
    "        rel = diff[mask] / y_ref.abs()[mask]\n",
    "        print(\"Log-mel masked max rel:\", rel.max().item(), \"mean rel:\", rel.mean().item())\n",
    "    else:\n",
    "        print(\"No elements exceed rel-error mask threshold in y_ref.\")\n",
    "\n",
    "    return {\n",
    "        \"power_max_abs\": (power_conv - power_ref).abs().max().item(),\n",
    "        \"power_mean_abs\": (power_conv - power_ref).abs().mean().item(),\n",
    "        \"mel_prelog_max_abs\": (mel_conv - mel_ref).abs().max().item(),\n",
    "        \"mel_prelog_mean_abs\": (mel_conv - mel_ref).abs().mean().item(),\n",
    "        \"logmel_max_abs\": diff.max().item(),\n",
    "        \"logmel_mean_abs\": diff.mean().item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9e27b1-9e1e-4fa6-a475-9a15383dc733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power max abs: 0.452392578125 mean abs: 0.014420101419091225\n",
      "Pre-log mel max abs: 0.46875 mean abs: 0.016031377017498016\n",
      "Log-mel max abs: 0.00011710822582244873 mean abs: 2.7025034796679392e-06\n",
      "Log-mel masked max rel: 0.002050897106528282 mean rel: 3.383140210644342e-06\n",
      "{'power_max_abs': 0.452392578125, 'power_mean_abs': 0.014420101419091225, 'mel_prelog_max_abs': 0.46875, 'mel_prelog_mean_abs': 0.016031377017498016, 'logmel_max_abs': 0.00011710822582244873, 'logmel_mean_abs': 2.7025034796679392e-06}\n"
     ]
    }
   ],
   "source": [
    "waveform = torch.randn(1, 32000, dtype=torch.float32)  # [B, T]  # [B, T]\n",
    "\n",
    "n_mels = 128\n",
    "sample_rate = 32000\n",
    "win_length=800\n",
    "hopsize=320\n",
    "n_fft=1024\n",
    "fmin=0.0\n",
    "fmax=16000.0\n",
    "\n",
    "extractor = LogMelSpectrogramConvSTFT(\n",
    "    n_mels=128, sr=32000, win_length=800, hopsize=320, n_fft=1024, fmin=0.0, fmax=16000.0\n",
    ").eval()\n",
    "mel = AugmentMelSTFT(n_mels=n_mels,\n",
    "                     sr=sample_rate,\n",
    "                     win_length=win_length,\n",
    "                     hopsize=hopsize,\n",
    "                     n_fft=n_fft,\n",
    "                     freqm=48,\n",
    "                     timem=192,\n",
    "                     fmin=fmin,\n",
    "                     fmax=fmax,\n",
    "                     fmin_aug_range=10, \n",
    "                     fmax_aug_range=2000\n",
    "                     \n",
    "                     )\n",
    "\n",
    "mel.eval()\n",
    "\n",
    "\n",
    "message = compare_logmel_stepwise(extractor,\n",
    "    mel,  # AugmentMelSTFT\n",
    "    waveform,\n",
    "    fmin,\n",
    "    fmax,\n",
    "    eps = 1e-5,\n",
    "    dtype = torch.float32)\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf30b6a-caa6-4c64-9b63-d254b72b53d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
