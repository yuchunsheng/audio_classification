{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9425c4f9-902b-4791-aefe-753b2904b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cb3d40-0f9c-46d2-a562-680ea7acb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d-based STFT that is ONNX-export-friendly.\n",
    "\n",
    "    Emulates torch.stft with:\n",
    "      - center=True  -> zero pad by n_fft//2 at both ends\n",
    "      - normalized=False\n",
    "      - return_complex=False (we output real/imag via two filter banks)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft: int = 1024,\n",
    "        hop_length: int = 320,\n",
    "        win_length: int = 800,\n",
    "        window: torch.Tensor | None = None,\n",
    "        pad_center: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert win_length <= n_fft, \"win_length must be <= n_fft\"\n",
    "\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.hop_length = int(hop_length)\n",
    "        self.win_length = int(win_length)\n",
    "        self.pad_center = bool(pad_center)\n",
    "\n",
    "        # Window\n",
    "        if window is None:\n",
    "            window = torch.hann_window(win_length, periodic=False, dtype=torch.float32)\n",
    "        else:\n",
    "            window = window.to(dtype=torch.float32)\n",
    "        self.register_buffer(\"window\", window, persistent=False)\n",
    "\n",
    "        # Build Fourier basis for positive frequencies [0 .. n_fft//2]\n",
    "        # Real kernels:  window[n] * cos(2πkn/N)\n",
    "        # Imag kernels: -window[n] * sin(2πkn/N)\n",
    "        \n",
    "        # Build Fourier basis for positive frequencies [0..n_fft//2]\n",
    "        num_bins = n_fft // 2 + 1\n",
    "        \n",
    "        # Center the window inside an n_fft frame\n",
    "        offset = (n_fft - win_length) // 2\n",
    "        win_full = torch.zeros(n_fft, dtype=torch.float32)\n",
    "        win_full[offset:offset+win_length] = self.window  # centered window\n",
    "        \n",
    "        # n over 0..n_fft-1, k over 0..num_bins-1\n",
    "        n = torch.arange(n_fft, dtype=torch.float32).unsqueeze(0)  # [1, n_fft]\n",
    "        k = torch.arange(num_bins, dtype=torch.float32).unsqueeze(1)  # [num_bins, 1]\n",
    "        ang = 2 * math.pi * k @ (n / float(n_fft))  # [num_bins, n_fft]\n",
    "        \n",
    "        cos_kernels = torch.cos(ang) * win_full      # [num_bins, n_fft]\n",
    "        sin_kernels = -torch.sin(ang) * win_full     # [num_bins, n_fft]\n",
    "        \n",
    "        weight = torch.cat([cos_kernels, sin_kernels], dim=0).unsqueeze(1)  # [2*num_bins, 1, n_fft]\n",
    "        self.register_buffer(\"fourier_basis\", weight.contiguous(), persistent=False)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, T] waveform\n",
    "\n",
    "        Returns:\n",
    "            stft_out: [B, num_bins, frames, 2]  where last dim is (real, imag)\n",
    "        \"\"\"\n",
    "        B, T = x.shape\n",
    "\n",
    "        # center=True -> zero pad by n_fft//2\n",
    "        if self.pad_center:\n",
    "            pad = self.n_fft // 2\n",
    "            x = F.pad(x, (pad, pad), mode=\"constant\", value=0.0)  # [B, T + 2*pad]\n",
    "\n",
    "        # Convolution to compute dot product with each Fourier kernel at each frame\n",
    "        # Input must be [B, 1, T]\n",
    "        y = F.conv1d(\n",
    "            x.unsqueeze(1),                       # [B, 1, T+pad*2]\n",
    "            self.fourier_basis,                   # [2*F, 1, win_length]\n",
    "            bias=None,\n",
    "            stride=self.hop_length,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "        )  # -> [B, 2*F, frames]\n",
    "\n",
    "        num_bins = self.n_fft // 2 + 1\n",
    "        frames = y.shape[-1]\n",
    "        y = y.view(B, 2, num_bins, frames)        # [B, 2, F, frames]\n",
    "        real = y[:, 0, :, :]                      # [B, F, frames]\n",
    "        imag = y[:, 1, :, :]                      # [B, F, frames]\n",
    "\n",
    "        # Pack to match torch.stft(return_complex=False) output layout\n",
    "        stft_out = torch.stack([real, imag], dim=-1)  # [B, F, frames, 2]\n",
    "        return stft_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6c5d3f-bea8-473b-964e-88142380677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes your ConvSTFT is patched for Option A: n_fft-length kernels with centered window\n",
    "class LogMelSpectrogramConvSTFT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_mels: int = 128,\n",
    "        sr: int = 32000,\n",
    "        win_length: int = 800,\n",
    "        hopsize: int = 320,\n",
    "        n_fft: int = 1024,\n",
    "        fmin: float = 0.0,\n",
    "        fmax: float | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if fmax is None:\n",
    "            fmax = sr // 2\n",
    "\n",
    "        self.n_mels = int(n_mels)\n",
    "        self.sr = int(sr)\n",
    "        self.win_length = int(win_length)\n",
    "        self.hopsize = int(hopsize)\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.fmin = float(fmin)\n",
    "\n",
    "        nyquist = sr // 2\n",
    "        if fmax is None:\n",
    "            fmax = nyquist\n",
    "        elif fmax > nyquist:\n",
    "            print(f\"[LogMel] fmax={fmax} > Nyquist={nyquist}. Clamping to Nyquist.\")\n",
    "            fmax = float(nyquist)\n",
    "        self.fmax = float(fmax)\n",
    "\n",
    "        assert 0.0 <= self.fmin < self.fmax <= (self.sr / 2), \\\n",
    "            f\"Invalid band: fmin={self.fmin}, fmax={self.fmax}, nyquist={self.sr/2}\"\n",
    "\n",
    "        # Pre-emphasis kernel y[t] = x[t] - 0.97*x[t-1]\n",
    "        self.register_buffer(\n",
    "            \"preemphasis_kernel\",\n",
    "            torch.tensor([[[-0.97, 1.0]]], dtype=torch.float32),\n",
    "            persistent=False\n",
    "        )\n",
    "\n",
    "        # STFT via conv: ConvSTFT must center win inside n_fft and use n_fft-length kernels internally\n",
    "        self.stft = ConvSTFT(\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hopsize,\n",
    "            win_length=self.win_length,\n",
    "            window=torch.hann_window(self.win_length, periodic=False, dtype=torch.float32),\n",
    "            pad_center=True,\n",
    "        )\n",
    "\n",
    "        # Kaldi mel filter bank (Nyquist excluded), then pad Nyquist\n",
    "        mel_bins, _ = torchaudio.compliance.kaldi.get_mel_banks(\n",
    "            num_bins=self.n_mels,\n",
    "            window_length_padded=self.n_fft,\n",
    "            sample_freq=self.sr,\n",
    "            low_freq=self.fmin,\n",
    "            high_freq=self.fmax,\n",
    "            vtln_low=100.0,\n",
    "            vtln_high=-500.0,\n",
    "            vtln_warp_factor=1.0,\n",
    "        )\n",
    "        mel_bins = F.pad(mel_bins, (0, 1), value=0.0)  # -> [n_mels, n_fft//2 + 1]\n",
    "        self.register_buffer(\"mel_basis\", mel_bins.to(torch.float32), persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Current behavior (length T-1) to match EfficientAT reference:\n",
    "        x = F.conv1d(x.unsqueeze(1), self.preemphasis_kernel).squeeze(1)\n",
    "\n",
    "        # STFT -> power\n",
    "        stft_out = self.stft(x)               # [B, F, frames, 2]\n",
    "        power = (stft_out ** 2).sum(dim=-1)   # [B, F, frames]\n",
    "\n",
    "        # Mel projection (use correct einsum string, keep dtype/device aligned)\n",
    "        mel_basis = self.mel_basis.to(dtype=power.dtype, device=power.device)  # [M, F]\n",
    "        mel = torch.einsum('mf,bft->bmt', mel_basis, power)                    # [B, M, T]\n",
    "\n",
    "        # Log compression + normalization\n",
    "        log_mel = (mel + 1e-5).log()\n",
    "        log_mel = (log_mel + 4.5) / 5.0\n",
    "        return log_mel\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def power_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.conv1d(x.unsqueeze(1), self.preemphasis_kernel).squeeze(1)\n",
    "        stft_out = self.stft(x)\n",
    "        power = (stft_out ** 2).sum(dim=-1)\n",
    "        return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a321cbec-e289-4ab6-a5c1-44ebdbf88b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecAugment(nn.Module):\n",
    "    \"\"\"\n",
    "    SpecAugment on log-mel (training only).\n",
    "    \"\"\"\n",
    "    def __init__(self, freqm: int = 48, timem: int = 192):\n",
    "        super().__init__()\n",
    "        self.freqm = (\n",
    "            nn.Identity() if freqm == 0 else torchaudio.transforms.FrequencyMasking(freqm, iid_masks=True)\n",
    "        )\n",
    "        self.timem = (\n",
    "            nn.Identity() if timem == 0 else torchaudio.transforms.TimeMasking(timem, iid_masks=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, log_mel: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training:\n",
    "            return log_mel\n",
    "        x = self.freqm(log_mel)\n",
    "        x = self.timem(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b059de64-41ac-4114-82be-0cde96b7b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMelEdgeProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    Re-project power spectrogram with randomized fmin/fmax during training.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_mels: int = 128,\n",
    "        sr: int = 32000,\n",
    "        n_fft: int = 1024,\n",
    "        fmin: float = 0.0,\n",
    "        fmax: float | None = None,\n",
    "        fmin_aug_range: int = 10,\n",
    "        fmax_aug_range: int = 1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        nyquist = sr // 2\n",
    "        if fmax is None:\n",
    "            fmax = nyquist\n",
    "        elif fmax > nyquist:\n",
    "            # Optional: print/log once so you know a clamp happened\n",
    "            print(f\"[LogMel] fmax={fmax} > Nyquist={nyquist}. Clamping to Nyquist.\")\n",
    "            fmax = float(nyquist)\n",
    "        \n",
    "        self.base_fmin = float(fmin)\n",
    "        self.base_fmax = float(fmax)\n",
    "        assert 0.0 <= self.base_fmin < self.base_fmax <= (sr / 2), f\"Invalid band: fmin={self.fmin}, fmax={self.fmax}, nyquist={self.sr/2}\"\n",
    "\n",
    "        assert fmin_aug_range >= 1\n",
    "        assert fmax_aug_range >= 1\n",
    "\n",
    "        self.n_mels = n_mels\n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        \n",
    "        self.fmin_aug_range = int(fmin_aug_range)\n",
    "        self.fmax_aug_range = int(fmax_aug_range)\n",
    "\n",
    "    def _build_mel_basis(self, fmin: float, fmax: float, device, dtype):\n",
    "        mb, _ = torchaudio.compliance.kaldi.get_mel_banks(\n",
    "            num_bins=self.n_mels,\n",
    "            window_length_padded=self.n_fft,\n",
    "            sample_freq=self.sr,\n",
    "            low_freq=fmin,\n",
    "            high_freq=fmax,\n",
    "            vtln_low=100.0,\n",
    "            vtln_high=-500.0,\n",
    "            vtln_warp_factor=1.0,\n",
    "        )\n",
    "        mb = torch.nn.functional.pad(mb, (0, 1), value=0.0)\n",
    "        return mb.to(device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, power_spec: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            fmin = self.base_fmin + torch.randint(self.fmin_aug_range, (1,), device=power_spec.device).item()\n",
    "            fmax = self.base_fmax + self.fmax_aug_range // 2 - torch.randint(self.fmax_aug_range, (1,), device=power_spec.device).item()\n",
    "            nyquist = self.sr // 2 \n",
    "            if fmax is None:\n",
    "                fmax = nyquist\n",
    "            elif fmax > nyquist:\n",
    "                # Optional: print/log once so you know a clamp happened\n",
    "                print(f\"[LogMel] fmax={fmax} > Nyquist={nyquist}. Clamping to Nyquist.\")\n",
    "                fmax = float(nyquist)\n",
    "        else:\n",
    "            fmin, fmax = self.base_fmin, self.base_fmax\n",
    "\n",
    "        mel_basis = self._build_mel_basis(fmin, fmax, device=power_spec.device, dtype=power_spec.dtype)\n",
    "        mel = torch.matmul(mel_basis, power_spec)  # [B, n_mels, frames]\n",
    "        return mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1789bd2-294e-4842-bd57-b79a926d29fc",
   "metadata": {},
   "source": [
    "#### for training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89de7332-e31a-4592-acfa-551e8653ed53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "extractor = LogMelSpectrogramConvSTFT(\n",
    "    n_mels=128, sr=32000, win_length=800, hopsize=320, n_fft=1024, fmin=0.0, fmax=16000.0\n",
    ").train()\n",
    "\n",
    "edge_aug = RandomMelEdgeProjector(\n",
    "    n_mels=128, sr=32000, n_fft=1024, fmin=0.0, fmax=16000.0, fmin_aug_range=10, fmax_aug_range=2000\n",
    ").train()\n",
    "\n",
    "mask_aug = MelSpecAugment(freqm=48, timem=192).train()\n",
    "\n",
    "waveform = torch.randn(1, 32000, dtype=torch.float32)  # [B, T]  # [B, T]\n",
    "# If you need to inspect the power spectrogram\n",
    "with torch.no_grad():\n",
    "    power = extractor.power_forward(waveform)   # [B, n_fft//2+1, frames]\n",
    "\n",
    "mel_lin = edge_aug(power)                          # randomized mel basis\n",
    "log_mel = (mel_lin + 1e-5).log()\n",
    "log_mel = (log_mel + 4.5) / 5.0\n",
    "log_mel = mask_aug(log_mel)\n",
    "print(log_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cacc55a-b94f-4b5d-8b8c-e1b6ac2d7e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9018,  0.5767,  0.3806,  ...,  0.4952,  0.5852,  0.4006],\n",
      "         [ 1.1505,  0.8254,  0.6293,  ...,  0.7439,  0.8338,  0.6493],\n",
      "         [ 1.0858,  0.4610,  0.4911,  ..., -0.3809,  0.7485,  0.5415],\n",
      "         ...,\n",
      "         [ 2.6883,  2.8038,  2.7573,  ...,  2.8198,  2.8366,  2.8351],\n",
      "         [ 2.6765,  2.6485,  2.8606,  ...,  2.9086,  2.8913,  2.7825],\n",
      "         [ 2.6966,  2.7689,  2.8318,  ...,  2.7054,  2.9003,  2.7768]]])\n"
     ]
    }
   ],
   "source": [
    "extractor.eval()\n",
    "waveform = torch.randn(1, 32000, dtype=torch.float32)  # [B, T]  # [B, T]\n",
    "log_mel = extractor(waveform)  # [B, n_mels, frames]\n",
    "print(log_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3821179-1507-4cbc-ab48-7b9066ec29b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported logmel_convstft.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:308: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/onnx/utils.py:657: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/onnx/utils.py:1127: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "model = LogMelSpectrogramConvSTFT(\n",
    "    n_mels=128, sr=32000, win_length=800, hopsize=320, n_fft=1024, fmin=0.0, fmax=16000.0\n",
    ").eval()\n",
    "\n",
    "dummy = torch.randn(1, 32000, dtype=torch.float32)  # [B, T]\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy,\n",
    "    \"logmel_convstft.onnx\",\n",
    "    opset_version=17,  # 13+ works; 17 recommended\n",
    "    input_names=[\"waveform\"],\n",
    "    output_names=[\"log_mel\"],\n",
    "    dynamic_axes={\"waveform\": {0: \"batch\", 1: \"time\"}, \"log_mel\": {0: \"batch\", 2: \"frames\"}},\n",
    ")\n",
    "print(\"Exported logmel_convstft.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a567afe-8945-4659-9af1-d34f1ba80e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "\n",
    "class AugmentMelSTFT(nn.Module):\n",
    "    def __init__(self, n_mels=128, sr=32000, win_length=800, hopsize=320, n_fft=1024, freqm=48, timem=192,\n",
    "                 fmin=0.0, fmax=None, fmin_aug_range=10, fmax_aug_range=2000):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        # adapted from: https://github.com/CPJKU/kagglebirds2020/commit/70f8308b39011b09d41eb0f4ace5aa7d2b0e806e\n",
    "\n",
    "        self.win_length = win_length\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.sr = sr\n",
    "        self.fmin = fmin\n",
    "        if fmax is None:\n",
    "            fmax = sr // 2 - fmax_aug_range // 2\n",
    "            print(f\"Warning: FMAX is None setting to {fmax} \")\n",
    "        self.fmax = fmax\n",
    "        self.hopsize = hopsize\n",
    "        self.register_buffer('window',\n",
    "                             torch.hann_window(win_length, periodic=False),\n",
    "                             persistent=False)\n",
    "        assert fmin_aug_range >= 1, f\"fmin_aug_range={fmin_aug_range} should be >=1; 1 means no augmentation\"\n",
    "        assert fmax_aug_range >= 1, f\"fmax_aug_range={fmax_aug_range} should be >=1; 1 means no augmentation\"\n",
    "        self.fmin_aug_range = fmin_aug_range\n",
    "        self.fmax_aug_range = fmax_aug_range\n",
    "\n",
    "        self.register_buffer(\"preemphasis_coefficient\", torch.as_tensor([[[-.97, 1]]]), persistent=False)\n",
    "        if freqm == 0:\n",
    "            self.freqm = torch.nn.Identity()\n",
    "        else:\n",
    "            self.freqm = torchaudio.transforms.FrequencyMasking(freqm, iid_masks=True)\n",
    "        if timem == 0:\n",
    "            self.timem = torch.nn.Identity()\n",
    "        else:\n",
    "            self.timem = torchaudio.transforms.TimeMasking(timem, iid_masks=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.conv1d(x.unsqueeze(1), self.preemphasis_coefficient).squeeze(1)\n",
    "        x = torch.stft(x, self.n_fft, hop_length=self.hopsize, win_length=self.win_length,\n",
    "                       center=True, normalized=False, window=self.window, return_complex=False)\n",
    "        x = (x ** 2).sum(dim=-1)  # power mag\n",
    "        fmin = self.fmin + torch.randint(self.fmin_aug_range, (1,)).item()\n",
    "        fmax = self.fmax + self.fmax_aug_range // 2 - torch.randint(self.fmax_aug_range, (1,)).item()\n",
    "        # don't augment eval data\n",
    "        if not self.training:\n",
    "            fmin = self.fmin\n",
    "            fmax = self.fmax\n",
    "\n",
    "        mel_basis, _ = torchaudio.compliance.kaldi.get_mel_banks(self.n_mels,  self.n_fft, self.sr,\n",
    "                                        fmin, fmax, vtln_low=100.0, vtln_high=-500., vtln_warp_factor=1.0)\n",
    "        mel_basis = torch.as_tensor(torch.nn.functional.pad(mel_basis, (0, 1), mode='constant', value=0),\n",
    "                                    device=x.device)\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            melspec = torch.matmul(mel_basis, x)\n",
    "\n",
    "        melspec = (melspec + 0.00001).log()\n",
    "\n",
    "        if self.training:\n",
    "            melspec = self.freqm(melspec)\n",
    "            melspec = self.timem(melspec)\n",
    "\n",
    "        melspec = (melspec + 4.5) / 5.  # fast normalization\n",
    "\n",
    "        return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2181232d-c85b-479d-a004-1f742054132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5383,  0.2939,  0.3629,  ...,  0.6083,  0.2326, -0.2799],\n",
      "         [ 0.7870,  0.5426,  0.6115,  ...,  0.8569,  0.4812, -0.0317],\n",
      "         [ 0.6747,  0.3803,  0.4762,  ..., -0.0573,  0.6308,  0.3580],\n",
      "         ...,\n",
      "         [ 2.6563,  2.8344,  2.7222,  ...,  2.8449,  2.6650,  2.9557],\n",
      "         [ 2.7153,  2.8136,  2.6892,  ...,  2.8037,  2.6342,  2.8036],\n",
      "         [ 2.7115,  2.7829,  2.7012,  ...,  2.7807,  2.7476,  2.8246]]])\n",
      "tensor([[[ 0.6461,  0.3027,  0.3629,  ...,  0.6083,  0.2326, -0.2852],\n",
      "         [ 0.8947,  0.5513,  0.6115,  ...,  0.8569,  0.4812, -0.0371],\n",
      "         [ 0.7495,  0.3793,  0.4762,  ..., -0.0573,  0.6308,  0.3376],\n",
      "         ...,\n",
      "         [ 2.7759,  2.8342,  2.7222,  ...,  2.8449,  2.6650,  2.9557],\n",
      "         [ 2.8732,  2.8141,  2.6892,  ...,  2.8037,  2.6342,  2.8036],\n",
      "         [ 2.8636,  2.7832,  2.7012,  ...,  2.7807,  2.7476,  2.8246]]])\n",
      "torch.Size([1, 128, 100]) torch.Size([1, 128, 100])\n",
      "tensor([[[-1.0774e-01, -8.7723e-03, -2.9802e-07,  ...,  1.0729e-06,\n",
      "          -7.7486e-07,  5.3262e-03],\n",
      "         [-1.0775e-01, -8.7735e-03, -2.9802e-07,  ...,  1.1325e-06,\n",
      "          -7.4506e-07,  5.3401e-03],\n",
      "         [-7.4800e-02,  1.0128e-03, -3.8743e-06,  ...,  5.4352e-06,\n",
      "           5.3644e-07,  2.0403e-02],\n",
      "         ...,\n",
      "         [-1.1965e-01,  1.9717e-04,  0.0000e+00,  ..., -1.1921e-06,\n",
      "           1.9073e-06,  3.8862e-05],\n",
      "         [-1.5785e-01, -5.1570e-04,  2.6226e-06,  ..., -2.1458e-06,\n",
      "           4.0531e-06, -1.2636e-05],\n",
      "         [-1.5204e-01, -3.8624e-04, -2.3842e-07,  ..., -3.8147e-06,\n",
      "          -7.1526e-07, -5.0306e-05]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycs/miniforge3/envs/audio/lib/python3.12/site-packages/torch/functional.py:709: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /pytorch/aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n",
      "/tmp/ipykernel_43991/1072670679.py:56: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "waveform = torch.randn(1, 32000, dtype=torch.float32)  # [B, T]  # [B, T]\n",
    "\n",
    "n_mels = 128\n",
    "sample_rate = 32000\n",
    "win_length=800\n",
    "hopsize=320\n",
    "n_fft=1024\n",
    "fmin=0.0\n",
    "fmax=16000.0\n",
    "\n",
    "extractor = LogMelSpectrogramConvSTFT(\n",
    "    n_mels=n_mels, sr=sample_rate, win_length=win_length, hopsize=hopsize, \n",
    "    n_fft=n_fft, fmin=fmin, fmax=fmax\n",
    ").eval()\n",
    "\n",
    "log_mel = extractor(waveform)  # [B, n_mels, frames]\n",
    "print(log_mel)\n",
    "\n",
    "# model to preprocess waveform into mel spectrograms\n",
    "mel = AugmentMelSTFT(n_mels=n_mels,\n",
    "                     sr=sample_rate,\n",
    "                     win_length=win_length,\n",
    "                     hopsize=hopsize,\n",
    "                     n_fft=n_fft,\n",
    "                     freqm=48,\n",
    "                     timem=192,\n",
    "                     fmin=fmin,\n",
    "                     fmax=fmax,\n",
    "                     fmin_aug_range=10, \n",
    "                     fmax_aug_range=2000\n",
    "                     \n",
    "                     )\n",
    "\n",
    "mel.eval()\n",
    "log_mel2 = mel(waveform)  # [B, n_mels, frames]\n",
    "print(log_mel2)\n",
    "print(log_mel.shape, log_mel2.shape)\n",
    "print(log_mel -log_mel2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2d034-7f58-4ad2-9d2e-43e162c6f986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
